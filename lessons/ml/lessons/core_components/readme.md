## **Core Components of AI & ML**

---

### **1. Learning**

| Type                         | Description                                                                |
| ---------------------------- | -------------------------------------------------------------------------- |
| **Supervised Learning**      | Learns from labeled data to predict outcomes.                              |
| **Unsupervised Learning**    | Learns patterns or structures from unlabeled data.                         |
| **Semi-Supervised Learning** | Uses both labeled and unlabeled data.                                      |
| **Reinforcement Learning**   | Learns by interacting with an environment and receiving rewards/penalties. |
| **Self-Supervised Learning** | Learns structure from data using pretext tasks.                            |

---

### **2. Reasoning**

| Type                    | Description                                               |
| ----------------------- | --------------------------------------------------------- |
| **Deductive Reasoning** | Applies general rules to reach specific conclusions.      |
| **Inductive Reasoning** | Infers general rules from specific examples or patterns.  |
| **Abductive Reasoning** | Infers the most likely explanation for observed evidence. |

> Often implemented in AI systems through logic-based approaches (e.g., Prolog), probabilistic models (e.g., Bayesian networks), or symbolic reasoning engines.

---

### **3. Problem Solving**

| Category                    | Description                                                              |
| --------------------------- | ------------------------------------------------------------------------ |
| **Search Algorithms**       | Find optimal solutions (e.g., A\*, BFS, DFS).                            |
| **Constraint Satisfaction** | Solves problems under defined rules/constraints (e.g., Sudoku).          |
| **Optimization**            | Finds best solution under cost/reward function (e.g., Gradient Descent). |

---

### **4. Perception**

| Modality          | Description                                                            |
| ----------------- | ---------------------------------------------------------------------- |
| **Vision**        | Object detection, image recognition, scene understanding.              |
| **Speech**        | Speech-to-text, speaker identification, audio understanding.           |
| **Touch**         | Tactile sensing in robotics and virtual interfaces.                    |
| **Sensor Fusion** | Combining multiple inputs (e.g., LIDAR + camera in self-driving cars). |

---

### **5. Language Understanding (NLP)**

| Task                    | Description                                                      |
| ----------------------- | ---------------------------------------------------------------- |
| **Syntax Analysis**     | Parsing sentences and analyzing grammatical structure.           |
| **Semantics**           | Understanding the meaning of words/sentences.                    |
| **Pragmatics**          | Interpreting context and intent behind language.                 |
| **Speech Recognition**  | Converting speech to text.                                       |
| **Language Generation** | Producing human-like language (e.g., text generation, chatbots). |
| **Translation**         | Translating between languages.                                   |

---

### **6. Knowledge Representation**

| Approach               | Description                                                         |
| ---------------------- | ------------------------------------------------------------------- |
| **Semantic Networks**  | Graph of concepts and their relationships.                          |
| **Ontologies**         | Formal structure of domain knowledge.                               |
| **Rules/Logic**        | IF-THEN rules to model expert knowledge.                            |
| **Frames and Scripts** | Data structures for representing stereotyped situations or objects. |
| **Knowledge Graphs**   | Structured graph-based storage of interrelated knowledge.           |

---

### **7. Planning & Decision Making**

| Component                | Description                                     |
| ------------------------ | ----------------------------------------------- |
| **Goal-based Planning**  | Formulates steps to achieve a desired state.    |
| **Reactive Systems**     | Makes decisions based on real-time stimuli.     |
| **Utility-based Agents** | Chooses actions to maximize utility or benefit. |
| **Multi-agent Planning** | Coordinates multiple intelligent agents.        |

---

### **8. Learning from Feedback**

| Method                          | Description                                                         |
| ------------------------------- | ------------------------------------------------------------------- |
| **Reward Functions**            | Define the goal in Reinforcement Learning.                          |
| **Policy Updates**              | Improve decision-making over time.                                  |
| **Value Functions**             | Estimate expected reward for a given state/action.                  |
| **Exploration vs Exploitation** | Balance between trying new actions and sticking to known good ones. |

---
